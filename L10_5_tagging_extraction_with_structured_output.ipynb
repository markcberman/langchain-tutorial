{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53573b5",
   "metadata": {},
   "source": [
    "# L10 — Tagging & Extraction (Modern LangChain Tools)\n",
    "\n",
    "This notebook converts a 2023-era *function-calling* example into **current (2025/2026) best practices**\n",
    "using **LangChain tools** and **`bind_tools`**.\n",
    "\n",
    "What this notebook teaches:\n",
    "- Why `functions=` / `function_call=` are legacy\n",
    "- How tools define **structured output contracts**\n",
    "- How models emit structured data via `tool_calls`\n",
    "- How this pattern scales to agents and LangGraph\n",
    "\n",
    "Environment assumptions:\n",
    "- Python 3.13\n",
    "- langchain / langchain-core / langchain-openai (v1)\n",
    "- gpt-5-mini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fd5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402fab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-5-mini\n"
     ]
    }
   ],
   "source": [
    "MODEL = os.environ.get(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\"Using model:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b7d26",
   "metadata": {},
   "source": [
    "## Why tools replace function calling\n",
    "\n",
    "Old notebooks relied on OpenAI-specific `functions` and `function_call`.\n",
    "Modern LangChain exposes **tools** as first-class primitives.\n",
    "\n",
    "Tools:\n",
    "- define the *shape* of valid output\n",
    "- let the model choose when to emit structured data\n",
    "- work uniformly across agents and graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4a9fd",
   "metadata": {},
   "source": [
    "## Tagging schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49efe01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingResult(BaseModel):\n",
    "    \"\"\"Structured tagging output.\"\"\"\n",
    "    sentiment: str = Field(description=\"Sentiment label, e.g. pos / neg / neutral\")\n",
    "    language: str = Field(description=\"ISO language code\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c559b",
   "metadata": {},
   "source": [
    "## Tagging tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7572d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\n",
    "    description=\"Tag text with sentiment and language.\",\n",
    "    args_schema=TaggingResult,\n",
    ")\n",
    "def tag_text(sentiment: str, language: str) -> TaggingResult:\n",
    "    # The model does the reasoning; the tool enforces structure.\n",
    "    return TaggingResult(sentiment=sentiment, language=language)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c9c41",
   "metadata": {},
   "source": [
    "## Bind tool to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools([tag_text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d400bc3",
   "metadata": {},
   "source": [
    "## Example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350b11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"non mi piace questo cibo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d38fea",
   "metadata": {},
   "source": [
    "## GOOD: Manual tool execution loop\n",
    "\n",
    "This shows exactly how tool calling works under the hood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23b564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI message:\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 220, 'prompt_tokens': 166, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CuHo750m8vRYC4da7vj0Fc19Qllov', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019b890c-792a-73a2-9582-96702887c0fb-0' tool_calls=[{'name': 'tag_text', 'args': {'sentiment': 'neg', 'language': 'it'}, 'id': 'call_W5r1p2JmTz0r2J8uYYyZaJbo', 'type': 'tool_call'}] usage_metadata={'input_tokens': 166, 'output_tokens': 220, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Tag the user's text with sentiment and language.\"),\n",
    "    HumanMessage(content=text),\n",
    "]\n",
    "\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "\n",
    "print(\"AI message:\")\n",
    "print(ai_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00854e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool call: {'name': 'tag_text', 'args': {'sentiment': 'neg', 'language': 'it'}, 'id': 'call_W5r1p2JmTz0r2J8uYYyZaJbo', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "tool_messages = []\n",
    "\n",
    "for call in ai_msg.tool_calls or []:\n",
    "    print(\"\\nTool call:\", call)\n",
    "\n",
    "    result = tag_text.invoke(call[\"args\"])\n",
    "    tool_messages.append(\n",
    "        ToolMessage(\n",
    "            content=result.model_dump_json(),\n",
    "            tool_call_id=call[\"id\"],\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11b7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final response:\n",
      "{\"sentiment\":\"neg\",\"language\":\"it\"}\n"
     ]
    }
   ],
   "source": [
    "final = model_with_tools.invoke(messages + [ai_msg] + tool_messages)\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(final.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75d738",
   "metadata": {},
   "source": [
    "## What to notice\n",
    "\n",
    "- The model *chose* to call the tool\n",
    "- `content` was empty during the tool call\n",
    "- Structured data lived in `tool_calls`\n",
    "- The final message used the tool output\n",
    "\n",
    "This is the modern replacement for `JsonOutputFunctionsParser`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb99b5",
   "metadata": {},
   "source": [
    "## Key takeaways\n",
    "\n",
    "- Tools replace OpenAI function calling\n",
    "- Pydantic schemas define output contracts\n",
    "- `bind_tools` is the standard integration point\n",
    "- This pattern is future-proof for agents and LangGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a51fc",
   "metadata": {},
   "source": [
    "## Modern equivalent of `JsonOutputFunctionsParser`: extract tool arguments from a chain\n",
    "\n",
    "In the legacy (2023) approach, you could do:\n",
    "\n",
    "```python\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "```\n",
    "\n",
    "That returned the parsed JSON **arguments** from the forced function call.\n",
    "\n",
    "In the modern tools approach, the structured payload lives in `AIMessage.tool_calls`.\n",
    "Below we build a **chain** that returns the tool arguments dict (similar to `JsonOutputFunctionsParser`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ebd941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Prompt (LCEL)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text with sentiment and language.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Model bound to tools\n",
    "model_with_tools_for_chain = llm.bind_tools([tag_text])\n",
    "\n",
    "def tool_args_parser(ai_msg):\n",
    "    \"\"\"Return the first tool-call arguments dict (like JsonOutputFunctionsParser did for functions).\"\"\"\n",
    "    calls = getattr(ai_msg, \"tool_calls\", None) or []\n",
    "    if not calls:\n",
    "        raise ValueError(f\"Model did not call a tool. Message was: {ai_msg}\")\n",
    "    return calls[0][\"args\"]\n",
    "\n",
    "# Runnable parser (modern equivalent)\n",
    "tool_args_parser_runnable = RunnableLambda(tool_args_parser)\n",
    "\n",
    "# Chain: prompt -> model(with tools) -> parse tool args\n",
    "tagging_chain_tools = prompt | model_with_tools_for_chain | tool_args_parser_runnable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d67c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain_tools.invoke({\"input\": \"non mi piace questo cibo\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae1107",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- This chain returns only the **structured arguments** (e.g., `{\"sentiment\": \"...\", \"language\": \"...\"}`),\n",
    "  just like `JsonOutputFunctionsParser` did.\n",
    "- If you want the full `AIMessage` (including tool call ids, etc.), run `prompt | model_with_tools_for_chain` without the parser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812bdef",
   "metadata": {},
   "source": [
    "## When to use `with_structured_output` (no tools)\n",
    "\n",
    "If you only need **structured extraction/classification** (no external actions),\n",
    "`with_structured_output` is often simpler than tools.\n",
    "\n",
    "It returns a **Pydantic object** directly — no manual tool loop, no tool-call parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b6fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class SentimentLanguage(BaseModel):\n",
    "    sentiment: str = Field(description=\"Sentiment of the text: pos, neg, or neutral\")\n",
    "    language: str = Field(description=\"ISO 639-1 language code, e.g. en, it, fr\")\n",
    "\n",
    "prompt_structured = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Analyze the user's text and extract sentiment and language.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "structured_llm = llm.with_structured_output(SentimentLanguage)\n",
    "\n",
    "tagging_chain_structured = prompt_structured | structured_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c036133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='neg' language='it'\n",
      "<class '__main__.SentimentLanguage'>\n",
      "{'sentiment': 'neg', 'language': 'it'}\n"
     ]
    }
   ],
   "source": [
    "result = tagging_chain_structured.invoke({\"input\": \"non mi piace questo cibo\"})\n",
    "print(result)\n",
    "print(type(result))\n",
    "print(result.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c21a7",
   "metadata": {},
   "source": [
    "### Key differences vs tools\n",
    "\n",
    "- **Tools + bind_tools**: best when you need the model to **trigger actions** (APIs, DB, functions) or do multi-step work.\n",
    "- **with_structured_output**: best when you just want **reliable structured data** from the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

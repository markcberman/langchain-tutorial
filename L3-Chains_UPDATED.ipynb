{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4960804",
   "metadata": {},
   "source": [
    "# L3 â€” Chains and Runnables (LangChain v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edf0ec",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This notebook uses **OpenAI (Python SDK v2) + LangChain v1**.\n",
    "\n",
    "## Prereqs\n",
    "1. Set your API key in the environment:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "2. Restart the kernel after setting env vars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05142c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure your key is set\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY in your environment before running.\"\n",
    "\n",
    "MODEL = \"gpt-5-mini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf5842",
   "metadata": {},
   "source": [
    "We'll build a small pipeline:\n",
    "1) generate an outline\n",
    "2) expand one section\n",
    "3) summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL)\n",
    "to_text = StrOutputParser()\n",
    "\n",
    "outline_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Create a compact outline with 4 bullet points.\"),\n",
    "    (\"user\", \"{topic}\")\n",
    "])\n",
    "\n",
    "expand_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Expand bullet point #2 into a short paragraph.\"),\n",
    "    (\"user\", \"Outline:\\n{outline}\")\n",
    "])\n",
    "\n",
    "summ_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Summarize in 2 sentences.\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "outline_chain = outline_prompt | llm | to_text\n",
    "expand_chain = expand_prompt | llm | to_text\n",
    "summ_chain = summ_prompt | llm | to_text\n",
    "\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | RunnableLambda(lambda x: x[\"topic\"])\n",
    "    | outline_chain\n",
    "    | (lambda outline: {\"outline\": outline, \"text\": outline})\n",
    "    | RunnableLambda(lambda d: d)\n",
    ")\n",
    "\n",
    "topic = \"How to write reliable prompts for LLMs\"\n",
    "outline = outline_chain.invoke({\"topic\": topic})\n",
    "expanded = expand_chain.invoke({\"outline\": outline})\n",
    "summary = summ_chain.invoke({\"text\": expanded})\n",
    "\n",
    "print(\"OUTLINE:\\n\", outline)\n",
    "print(\"\\nEXPANDED:\\n\", expanded)\n",
    "print(\"\\nSUMMARY:\\n\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "title": "L3-Chains_UPDATED.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# LangChain Learning Notebooks

This repository contains a set of **hands-on Jupyter notebooks** demonstrating modern **LangChain v1.x** patterns using OpenAI models, including:

- Chains
- Memory
- Question Answering
- Retrieval-Augmented Generation (RAG)
- Evaluation
- Tool-calling Agents

The project is designed for **Python 3.13**, uses **Conda** to manage the base runtime, and **uv** to track and lock Python dependencies via `pyproject.toml` and `uv.lock`.

---

## Quick Start (TL;DR)

```bash
# 1. Create and activate the conda environment
conda env create -f environment.yaml
conda activate langchain

# 2. Install Python dependencies (tracked by uv)
uv sync

# 3. Register the Jupyter kernel (one-time)
python -m ipykernel install --user --name langchain --display-name "Python (langchain)"

# 4. Launch JupyterLab
jupyter lab
```

Open any notebook and select the **Python (langchain)** kernel.

---

## Repository Structure

```
.
├── environment.yaml                 # Conda environment definition
├── pyproject.toml                   # Project metadata + Python deps (tracked by uv)
├── uv.lock                          # Resolved dependency lockfile (generated by uv)
├── README.md
├── L2-Memory_UPDATED.ipynb           # Memory patterns
├── L3-Chains_UPDATED.ipynb           # Chains and runnables
├── L4-QnA_UPDATED.ipynb              # Q&A with prompts and retrievers
├── L5-Evaluation_UPDATED.ipynb       # Evaluation with LangChain evaluators
├── L5_5_rag_and_rag_eval_outdoor_catalog.ipynb  # End-to-end RAG + eval example
└── L6-Agents_UPDATED.ipynb           # Tool-calling agents (LangChain v1)
```

---

## Notebook Overview

### L2 – Memory
Demonstrates conversational memory patterns in LangChain v1 and how memory integrates with runnables.

### L3 – Chains
Shows how to build and compose chains using LangChain v1’s runnable interface.

### L4 – Q&A
Implements question answering flows using prompts and retrieval.

### L5 – Evaluation
Covers response evaluation using LangChain evaluation utilities.

### L5.5 – RAG + Evaluation
A complete RAG pipeline using ChromaDB for vector storage and LangChain evaluation.

### L6 – Agents
Demonstrates **tool-calling agents** using:
- `create_agent` (LangChain v1 API)
- DuckDuckGo search (`ddgs`)
- Custom Python tools

Agents are invoked using the **LangGraph-style state interface**:

```python
agent.invoke({
    "messages": [HumanMessage(content="Find the tallest building and multiply its height by 2")]
})
```

---

## Environment & Dependency Model

This project intentionally separates concerns:

- **Conda** manages:
  - Python 3.13
  - JupyterLab
  - System libraries (SQLite, OpenSSL) required by Chroma
- **uv** manages:
  - Python package resolution
  - Dependency locking (`uv.lock`)

This avoids common dependency conflicts while keeping installs reproducible.

---

## Setup (Detailed)

### 1. Create the Conda environment

```bash
conda env create -f environment.yaml
conda activate langchain
```

### 2. Install Python dependencies

```bash
uv sync
```

This installs **all required Python packages** listed in `pyproject.toml` using versions pinned in `uv.lock`.

> You do **not** need to manually install individual Python packages.

### 3. Jupyter kernel

```bash
python -m ipykernel install --user --name langchain --display-name "Python (langchain)"
```

### 4. Run notebooks

```bash
jupyter lab
```

---

## API Keys

Set your OpenAI API key:

```bash
export OPENAI_API_KEY=your-key-here
```

Or create a `.env` file:

```
OPENAI_API_KEY=your-key-here
```

---

## Troubleshooting

### Agent gives nonsensical answers
- Ensure you invoke agents with **messages**, not `input`:
  ```python
  agent.invoke({"messages": [HumanMessage(content="...")]})
  ```
- Restart the kernel and run notebooks top-to-bottom to avoid stale state.
- Use a strong system prompt or `bind_tools(..., tool_choice="required")`.

### Tools not being called
- Confirm tool invocation using `StdOutCallbackHandler`.
- Make sure the model supports tool calling.
- Verify that `ddgs` is installed in the same environment as Jupyter.

### Package import errors
- Confirm you are running the **Python (langchain)** kernel.
- Run:
  ```bash
  uv pip list --system
  ```
  to verify packages are installed in the active conda environment.

### Dependency drift
- Do not use `pip install` directly.
- Update dependencies via:
  ```bash
  uv add <package>
  uv lock
  uv sync
  ```

---

## Requirements

- macOS or Linux
- Conda (Miniconda or Anaconda)
- Python 3.13
- OpenAI API key

---

## License

Educational / experimental use.

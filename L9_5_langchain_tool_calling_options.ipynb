{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449fd328",
   "metadata": {},
   "source": [
    "# LangChain Tools + Agents + LangGraph (Good / Better / Best)\n",
    "\n",
    "This notebook follows **current production best practices (2026)**:\n",
    "\n",
    "- **Good** → Manual tool execution (explicit, debuggable)\n",
    "- **Better** → **`create_agent`** (modern LangChain agent API, no executor)\n",
    "- **Best** → Explicit **LangGraph** workflow (`StateGraph`)\n",
    "\n",
    "Assumes:\n",
    "- `langchain` (modern v1+)\n",
    "- `langchain-core`, `langchain-openai`\n",
    "- `langgraph` + `langgraph-prebuilt`\n",
    "- `OPENAI_API_KEY` set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b941fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    BaseMessage,\n",
    ")\n",
    "\n",
    "MODEL = os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "print(\"Using model:\", MODEL)\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "SYSTEM = \"You are a helpful assistant. Use tools when appropriate.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c85915",
   "metadata": {},
   "source": [
    "## 1) Pydantic argument schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a3aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherSearchArgs(BaseModel):\n",
    "    airport_code: str = Field(description=\"Airport code (e.g., SFO)\")\n",
    "\n",
    "\n",
    "class ArtistSearchArgs(BaseModel):\n",
    "    artist_name: str = Field(description=\"Artist name\")\n",
    "    n: int = Field(default=3, description=\"Number of songs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb82bc4",
   "metadata": {},
   "source": [
    "## 2) Tools (`@tool`, name inferred from function name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e1a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"Get demo weather for an airport.\", args_schema=WeatherSearchArgs)\n",
    "def WeatherSearch(airport_code: str) -> str:\n",
    "    return f\"Weather at {airport_code}: sunny, 23°C\"\n",
    "\n",
    "\n",
    "@tool(description=\"Get demo songs by an artist.\", args_schema=ArtistSearchArgs)\n",
    "def ArtistSearch(artist_name: str, n: int = 3) -> List[str]:\n",
    "    demo = {\n",
    "        \"taylor swift\": [\"Anti-Hero\", \"Blank Space\", \"Cruel Summer\", \"Shake It Off\"],\n",
    "        \"daft punk\": [\"One More Time\", \"Harder, Better, Faster, Stronger\", \"Get Lucky\"],\n",
    "    }\n",
    "    return demo.get(artist_name.lower(), [\"(no results)\"])[:n]\n",
    "\n",
    "\n",
    "tools = [WeatherSearch, ArtistSearch]\n",
    "tool_registry = {t.name: t for t in tools}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce2a90",
   "metadata": {},
   "source": [
    "## Good: Manual tool execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb542e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual(question: str) -> str:\n",
    "    bound = llm.bind_tools(tools)\n",
    "\n",
    "    ai_msg = bound.invoke([\n",
    "        SystemMessage(content=SYSTEM),\n",
    "        HumanMessage(content=question),\n",
    "    ])\n",
    "\n",
    "    tool_messages = []\n",
    "    for call in ai_msg.tool_calls or []:\n",
    "        result = tool_registry[call[\"name\"]].invoke(call[\"args\"])\n",
    "        tool_messages.append(ToolMessage(content=str(result), tool_call_id=call[\"id\"]))\n",
    "\n",
    "    final = bound.invoke([\n",
    "        SystemMessage(content=SYSTEM),\n",
    "        HumanMessage(content=question),\n",
    "        ai_msg,\n",
    "        *tool_messages,\n",
    "    ])\n",
    "    return final.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0144a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather at San Francisco International Airport (SFO) is sunny with a temperature of 23°C.\n",
      "Here are three songs by Taylor Swift:\n",
      "\n",
      "1. Anti-Hero\n",
      "2. Blank Space\n",
      "3. Cruel Summer\n"
     ]
    }
   ],
   "source": [
    "print(run_manual(\"what is the weather at SFO?\"))\n",
    "print(run_manual(\"what are three songs by Taylor Swift?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915f204",
   "metadata": {},
   "source": [
    "## Better: Modern LangChain Agent (`create_agent`)\n",
    "\n",
    "This is the **recommended agent API**.\n",
    "- No `AgentExecutor`\n",
    "- No deprecated helpers\n",
    "- Tools auto-run internally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740660d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather at San Francisco International Airport (SFO) is sunny with a temperature of 23°C.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=SYSTEM,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather at SFO?\"}]})\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2402f45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three songs by Taylor Swift:\n",
      "\n",
      "1. Anti-Hero\n",
      "2. Blank Space\n",
      "3. Cruel Summer\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what are three songs by Taylor Swift?\"}]})\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c1f79",
   "metadata": {},
   "source": [
    "## Best: Explicit LangGraph workflow\n",
    "\n",
    "Use this when you need:\n",
    "- deterministic routing\n",
    "- validation / guardrails\n",
    "- retries or approvals\n",
    "- long-running workflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0698dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Best: Explicit LangGraph workflow (StateGraph) ---\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Bind tools to the model used inside the graph\n",
    "graph_llm = llm.bind_tools(tools)\n",
    "\n",
    "# 1) State uses the add_messages reducer so message merges preserve tool_call_id/tool ids\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "# 2) LLM node returns ONLY the new message; reducer appends it\n",
    "def llm_node(state: GraphState) -> GraphState:\n",
    "    resp = graph_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [resp]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "def route_after_llm(state: GraphState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    if last.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "sg = StateGraph(GraphState)\n",
    "sg.add_node(\"llm\", llm_node)\n",
    "sg.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Modern entry edge syntax\n",
    "sg.add_edge(START, \"llm\")\n",
    "sg.add_conditional_edges(\"llm\", route_after_llm, {\"tools\": \"tools\", END: END})\n",
    "sg.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "app = sg.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c27468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather at San Francisco International Airport (SFO) is sunny with a temperature of 23°C.\n"
     ]
    }
   ],
   "source": [
    "out = app.invoke({\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=SYSTEM),\n",
    "        HumanMessage(content=\"what is the weather at SFO?\"),\n",
    "    ]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d86374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three songs by Taylor Swift:\n",
      "\n",
      "1. Anti-Hero\n",
      "2. Blank Space\n",
      "3. Cruel Summer\n"
     ]
    }
   ],
   "source": [
    "out = app.invoke({\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=SYSTEM),\n",
    "        HumanMessage(content=\"what are three songs by Taylor Swift?\"),\n",
    "    ]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

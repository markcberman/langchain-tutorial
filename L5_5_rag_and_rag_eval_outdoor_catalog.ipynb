{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad8e5a9",
   "metadata": {},
   "source": [
    "# RAG + RAG Evaluation (LangChain) using Chroma (Python 3.13 friendly) + `OutdoorClothingCatalog_1000.csv` + **gpt-5-mini**\n",
    "\n",
    "You confirmed these imports work in your Python 3.13 conda env:\n",
    "\n",
    "```python\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "```\n",
    "\n",
    "So this notebook uses **Chroma** instead of FAISS.\n",
    "\n",
    "It demonstrates:\n",
    "1. **RAG** over the CSV: load rows → index in Chroma → retrieve top-k → answer with GPT-5 mini using only retrieved context.\n",
    "2. **RAG groundedness evaluation**: LLM-as-a-judge with a small rubric, returning structured output via `PydanticOutputParser`.\n",
    "\n",
    "## Assumptions\n",
    "- `OutdoorClothingCatalog_1000.csv` sits in the **same directory** as this notebook (e.g. `~/opensource/langchain/`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a383751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_OPENAI = True\n",
      "MODEL = gpt-5-mini\n",
      "CSV_PATH = OutdoorClothingCatalog_1000.csv\n",
      "CHROMA_DIR = .chroma_outdoor_catalog\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "MODEL = os.environ.get(\"RAG_DEMO_MODEL\", \"gpt-5-mini\")\n",
    "USE_OPENAI = bool(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "CSV_PATH = os.environ.get(\"RAG_DEMO_CSV_PATH\", \"OutdoorClothingCatalog_1000.csv\")\n",
    "CHROMA_DIR = os.environ.get(\"RAG_DEMO_CHROMA_DIR\", \".chroma_outdoor_catalog\")\n",
    "\n",
    "print(\"USE_OPENAI =\", USE_OPENAI)\n",
    "print(\"MODEL =\", MODEL)\n",
    "print(\"CSV_PATH =\", CSV_PATH)\n",
    "print(\"CHROMA_DIR =\", CHROMA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db83f4",
   "metadata": {},
   "source": [
    "## Load the CSV into LangChain `Document`s\n",
    "\n",
    "Each row becomes a `Document`. For product catalogs this is a good default: one product = one retrievable unit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc90bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n",
      "Columns: ['Unnamed: 0', 'name', 'description']\n",
      "Documents: 1000\n",
      "\n",
      "Example:\n",
      " Product: Women's Campside Oxfords\n",
      "Description: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \n",
      "\n",
      "Size & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \n",
      "\n",
      "Specs: Approx. weight: 1 lb.1 oz. per pair. \n",
      "\n",
      "Construction: Soft canvas material for \n",
      "Metadata: {'row_index': 0, 'name': \"Women's Campside Oxfords\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# We'll use name/description if present; otherwise fall back to \"all columns\" text.\n",
    "has_name = \"name\" in df.columns\n",
    "has_desc = \"description\" in df.columns\n",
    "\n",
    "def row_to_text(row) -> str:\n",
    "    if has_name or has_desc:\n",
    "        name = str(row.get(\"name\", \"\")).strip() if has_name else \"\"\n",
    "        desc = str(row.get(\"description\", \"\")).strip() if has_desc else \"\"\n",
    "        if name and desc:\n",
    "            return f\"Product: {name}\\nDescription: {desc}\"\n",
    "        if name:\n",
    "            return f\"Product: {name}\"\n",
    "        return desc\n",
    "    # fallback: stringify all columns\n",
    "    parts = []\n",
    "    for col, val in row.items():\n",
    "        if pd.isna(val):\n",
    "            continue\n",
    "        parts.append(f\"{col}: {val}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "documents: List[Document] = []\n",
    "for i, row in df.iterrows():\n",
    "    text = row_to_text(row)\n",
    "    meta = {\"row_index\": int(i)}\n",
    "    if has_name and pd.notna(row.get(\"name\", None)):\n",
    "        meta[\"name\"] = str(row[\"name\"])\n",
    "    documents.append(Document(page_content=text, metadata=meta))\n",
    "\n",
    "print(\"Documents:\", len(documents))\n",
    "print(\"\\nExample:\\n\", documents[0].page_content[:400])\n",
    "print(\"Metadata:\", documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24fedb",
   "metadata": {},
   "source": [
    "## Build a Chroma vector store + retriever\n",
    "\n",
    "- Uses `OpenAIEmbeddings` if `OPENAI_API_KEY` is present.\n",
    "- Otherwise uses `FakeEmbeddings` so you can still run the pipeline without API calls.\n",
    "\n",
    "Chroma persists its data to `CHROMA_DIR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80209a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] EcoFlex 3L Storm Pants\n",
      "Product: EcoFlex 3L Storm Pants\n",
      "Description: Our new TEK O2 technology makes our four-season waterproof pants even more breathable. It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather. Size & Fit \n",
      "\n",
      "[2] EcoFlex 3L Storm Pants\n",
      "Product: EcoFlex 3L Storm Pants\n",
      "Description: Our new TEK O2 technology makes our four-season waterproof pants even more breathable. It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather. Size & Fit \n",
      "\n",
      "[3] EcoFlex 3L Storm Pants\n",
      "Product: EcoFlex 3L Storm Pants\n",
      "Description: Our new TEK O2 technology makes our four-season waterproof pants even more breathable. It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather. Size & Fit \n",
      "\n",
      "[4] Women's Waterproof Hiking Trousers\n",
      "Product: Women's Waterproof Hiking Trousers\n",
      "Description: Our waterproof rain pants have been redesigned to be tougher and more durable, featuring a laminate interior for rugged protection and breathable comfort.\n",
      "\n",
      "Size & Fit\n",
      "\n",
      "Slightly Fitted \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "\n",
    "# Embeddings\n",
    "if USE_OPENAI:\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings()  # default embedding model\n",
    "else:\n",
    "    embeddings = FakeEmbeddings(size=768)\n",
    "\n",
    "# Build / load Chroma\n",
    "# Note: if you re-run with different embeddings or docs, consider deleting CHROMA_DIR first.\n",
    "vs = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=CHROMA_DIR,\n",
    ")\n",
    "\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Quick check\n",
    "question = \"What are the key features of the EcoFlex 3L Storm Pants?\"\n",
    "hits = retriever.invoke(question)\n",
    "for i, d in enumerate(hits, 1):\n",
    "    print(f\"[{i}] {d.metadata.get('name','(no name)')}\")\n",
    "    print(d.page_content[:240], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618c733",
   "metadata": {},
   "source": [
    "## RAG answer generation (GPT-5 mini)\n",
    "\n",
    "We force the assistant to answer using **only** the retrieved context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ef8a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context (truncated):\n",
      "\n",
      "- Product: EcoFlex 3L Storm Pants\n",
      "Description: Our new TEK O2 technology makes our four-season waterproof pants even more breathable. It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather. Size & Fit: Slightly Fitted through hip and thigh. \n",
      "\n",
      "Why We Love It: Our state-of-the-art TEK O2 technology offers the most breathability we've ever tested. Great as ski pants, they're ideal for a variety of outdoor activities year-round. Plus, they're loaded with features outdoor enthusiasts appreciate, including weather-blocking gaiters and handy side zips. Air In. Water Out. See how our air-permeable TEK O2 technology keeps you dry and comfortable. \n",
      "\n",
      "Fabric & Care: 100% nylon, exclusive of trim. Machine wash and dry. \n",
      "\n",
      "Additional Features: Three-layer shell delivers waterproof protection. Brand new TEK O2 technology provides enhanced breathability. Interior gaiters keep out rain and snow. Full side zips for easy on/off over boots. Two zippered hand pockets. Thigh pocket. Imported.\n",
      "\n",
      " – Official Supplier to the U.S. Ski Team\n",
      "THEIR WILL\n",
      "\n",
      "- Product: EcoFlex 3L Storm Pants\n",
      "Description: Our new TEK O2 technology makes our four-season waterproof pants even m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant.\\n\"\n",
    "     \"Use ONLY the provided CONTEXT to answer.\\n\"\n",
    "     \"If the answer is not in the context, say you don't know.\\n\"),\n",
    "    (\"user\", \"QUESTION:\\n{question}\\n\\nCONTEXT:\\n{context}\\n\\nANSWER:\")\n",
    "])\n",
    "\n",
    "def format_context(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join([f\"- {d.page_content}\" for d in docs])\n",
    "\n",
    "context_docs = retriever.invoke(question)\n",
    "context_text = format_context(context_docs)\n",
    "\n",
    "print(\"Retrieved context (truncated):\\n\")\n",
    "print(context_text[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b00d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What are the key features of the EcoFlex 3L Storm Pants?\n",
      "\n",
      "ANSWER:\n",
      " Key features of the EcoFlex 3L Storm Pants\n",
      "\n",
      "- TEK O2 technology: air‑permeable membrane for enhanced breathability (\"Air In. Water Out.\")\n",
      "- Four‑season waterproof protection via a three‑layer shell\n",
      "- Slightly fitted through hip and thigh\n",
      "- Interior/weather‑blocking gaiters to keep out rain and snow\n",
      "- Full side zips for easy on/off over boots\n",
      "- Two zippered hand pockets plus a zippered thigh pocket\n",
      "- Fabric/care: 100% nylon (exclusive of trim); machine wash and dry; imported\n",
      "- Designed for year‑round outdoor use (including skiing); Official Supplier to the U.S. Ski Team\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if USE_OPENAI:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "    rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "    answer = rag_chain.invoke({\"question\": question, \"context\": context_text})\n",
    "else:\n",
    "    def offline_answer(question: str, context: str) -> str:\n",
    "        lines = [ln.strip(\"- \").strip() for ln in context.splitlines() if ln.strip().startswith(\"-\")]\n",
    "        if not lines:\n",
    "            return \"I don't know based on the provided context.\"\n",
    "        return \"Based on the retrieved catalog rows: \" + \" \".join(lines[:2])\n",
    "    answer = offline_answer(question, context_text)\n",
    "\n",
    "print(\"QUESTION:\", question)\n",
    "print(\"\\nANSWER:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c1ab8",
   "metadata": {},
   "source": [
    "## Groundedness evaluation (LLM-as-a-judge) with structured output\n",
    "\n",
    "Rubric:\n",
    "- `grounded=True` if the answer is supported by the retrieved context.\n",
    "- `grounded=False` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfbae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Groundedness(BaseModel):\n",
    "    grounded: bool = Field(..., description=\"True if the answer is supported by the context.\")\n",
    "    rationale: str = Field(..., description=\"1-3 sentences explaining why.\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Groundedness)\n",
    "\n",
    "judge_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a judge evaluating whether an ANSWER is supported by the given CONTEXT.\\n\"\n",
    "     \"If the answer relies on facts not in the context, mark grounded=false.\\n\"\n",
    "     \"{format_instructions}\"),\n",
    "    (\"user\", \"CONTEXT:\\n{context}\\n\\nANSWER:\\n{answer}\")\n",
    "]).partial(format_instructions=parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa0e5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Groundedness(grounded=False, rationale=\"Most bullets match the provided description (TEK O2 breathability, three-layer waterproof shell, fit, gaiters, full side zips, fabric/care, year‑round/ ski use, supplier). However, the answer states the thigh pocket is zippered — the context lists only a 'thigh pocket' (no mention that it is zippered), so that detail is not supported.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if USE_OPENAI:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    judge_llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "    judge = judge_prompt | judge_llm | parser\n",
    "    verdict = judge.invoke({\"context\": context_text, \"answer\": answer})\n",
    "else:\n",
    "    def offline_judge(context: str, answer: str) -> Groundedness:\n",
    "        ctx = context.lower()\n",
    "        ans = answer.lower()\n",
    "        tokens = [t.strip(\".,;:!?()[]\\\"'\") for t in ans.split() if len(t) > 4]\n",
    "        missing = [t for t in tokens if t and t not in ctx]\n",
    "        grounded = len(missing) < max(10, len(tokens)//2 + 1)\n",
    "        rationale = (\n",
    "            \"Offline heuristic: most key terms appear in the retrieved context.\"\n",
    "            if grounded else\n",
    "            \"Offline heuristic: many key terms do not appear in the retrieved context, suggesting unsupported claims.\"\n",
    "        )\n",
    "        return Groundedness(grounded=grounded, rationale=rationale)\n",
    "\n",
    "    verdict = offline_judge(context_text, answer)\n",
    "\n",
    "verdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38b318",
   "metadata": {},
   "source": [
    "## Batch evaluation (optional)\n",
    "\n",
    "Run retrieval → answer → judge repeatedly and summarize groundedness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4b38be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the key features of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'Key features of the EcoFlex 3L Storm Pants\\n\\n- TEK O2 technology: air‑permeable, brand‑new system that provides enhanced breathability (\"Air In. Water Out.\").\\n- Three‑layer shell for waterproof protection.\\n- Interior/weather‑blocking gaiters to keep out rain and snow.\\n- Full side zips for easy on/off over boots.\\n- Two zippered hand pockets and an additional thigh pocket.\\n- Four‑season use — great as ski pants and for year‑round outdoor activities.\\n- Fit: slightly fitted through hip and thigh.\\n- Fabric & care: 100% nylon (exclusive of trim); machine wash and dry.\\n- Imported; official supplier to the U.S. Ski Team.',\n",
       "  'grounded': True,\n",
       "  'rationale': \"Each listed feature appears explicitly in the provided product descriptions (TEK O2 breathability and 'Air In. Water Out.', three-layer shell, interior gaiters, full side zips, pocket details, four-season/ski use, fit, fabric & care, 'Imported' and 'Official Supplier to the U.S. Ski Team'). No unsupported claims were added.\",\n",
       "  'top_hits': ['EcoFlex 3L Storm Pants',\n",
       "   'EcoFlex 3L Storm Pants',\n",
       "   'EcoFlex 3L Storm Pants',\n",
       "   \"Women's Waterproof Hiking Trousers\"]},\n",
       " {'question': 'Which product mentions sealed seams and waterproofing?',\n",
       "  'answer': 'None of the provided product descriptions mention sealed seams. Both the TrailGuard Waterproof Gore-Tex Jacket and the Outdoor Adventurer Rain Shell mention waterproofing, but sealed seams are not mentioned for any product.',\n",
       "  'grounded': True,\n",
       "  'rationale': \"The provided product descriptions list features (Gore-Tex laminate, DWR, vents, hood adjustments, pockets, recycled nylon, etc.) but do not mention 'sealed seams' or equivalent phrasing. Therefore the claim that sealed seams are not mentioned is supported by the context.\",\n",
       "  'top_hits': ['TrailGuard Waterproof Gore-Tex Jacket',\n",
       "   'TrailGuard Waterproof Gore-Tex Jacket',\n",
       "   'TrailGuard Waterproof Gore-Tex Jacket',\n",
       "   'Outdoor Adventurer Rain Shell']},\n",
       " {'question': 'Is there any jacket described as insulated or warm? If so, which one and what does it say?',\n",
       "  'answer': 'Yes.\\n\\n- Ladies\\' Luxury Snow Coat — \"This insulated soft-shell jacket is extra rugged, with just the right amount of stretch... It provides light activity protection up to 30° and moderate activity protection up to -20°... with ultralight, ultrawarm PrimaLoft insulation to keep you comfortable and dry on the slopes.\"\\n\\n- Arctic Wind Insulated Pullover — \"We took the classic anorak look and combined it with the exceptional warmth of PrimaLoft® insulation... Light activity: to 45°  Moderate activity: to -5°... Packed with 40 grams of ultralight, ultrawarm PrimaLoft insulation.\"',\n",
       "  'grounded': True,\n",
       "  'rationale': \"Both quoted excerpts appear verbatim in the provided context. The Ladies' Luxury Snow Coat description includes the lines about activity protection (light to 30°, moderate to -20°) and PrimaLoft insulation, and the Arctic Wind Insulated Pullover description includes the PrimaLoft wording, the activity temperature ratings (light to 45°, moderate to -5°), and the 'Packed with 40 grams' statement.\",\n",
       "  'top_hits': [\"Ladies' Luxury Snow Coat\",\n",
       "   \"Ladies' Luxury Snow Coat\",\n",
       "   \"Ladies' Luxury Snow Coat\",\n",
       "   'Arctic Wind Insulated Pullover']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "questions = [\n",
    "    \"What are the key features of the EcoFlex 3L Storm Pants?\",\n",
    "    \"Which product mentions sealed seams and waterproofing?\",\n",
    "    \"Is there any jacket described as insulated or warm? If so, which one and what does it say?\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for q in questions:\n",
    "    ctx_docs = retriever.invoke(q)\n",
    "    ctx = format_context(ctx_docs)\n",
    "\n",
    "    if USE_OPENAI:\n",
    "        ans = rag_chain.invoke({\"question\": q, \"context\": ctx})\n",
    "        v = judge.invoke({\"context\": ctx, \"answer\": ans})\n",
    "    else:\n",
    "        ans = offline_answer(q, ctx)\n",
    "        v = offline_judge(ctx, ans)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": ans,\n",
    "        \"grounded\": v.grounded,\n",
    "        \"rationale\": v.rationale,\n",
    "        \"top_hits\": [d.metadata.get(\"name\", \"\") for d in ctx_docs],\n",
    "    })\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d149c5-d9d3-46b3-9cd8-426fbafda81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
